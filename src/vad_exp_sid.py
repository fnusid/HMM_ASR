#!/Users/sidharth/opt/anaconda3/envs/neural/bin/python
'''
This code was generated by @Sidharth. This code includes the implementation of VAD using sound enerygy and zero crossing methods. 

Usage:

Input : 
Output : 
'''

import tempfile
import numpy as np
import sounddevice as sd
import soundfile as sf
import torchaudio
import pyaudio
import pdb
import json
import os
from hmm_sid import test
import librosa
from sklearn.preprocessing import MinMaxScaler
import time

import matplotlib.pyplot as plt


def cal_energy(audio_signal, sr):
    energy = np.mean(np.square(audio_signal))
    return energy


def zero_cross(audio_signal, sr):
    sign_diff = np.abs(np.diff(np.sign(audio_signal)))
    zc_rate = 0.5 * np.mean(sign_diff)
    return zc_rate

    
     
    

if __name__ == '__main__':
    print("Recording and processing...")
    sample_rate = 22050
    audio_chunk = 44100
    format = pyaudio.paInt16
    channels = 1
    buffer_seconds = 1 # Length of the buffer in seconds
    p = pyaudio.PyAudio()
    stream = p.open(format=format, channels=channels, rate=sample_rate, input=True, frames_per_buffer=audio_chunk)

    # Buffer to store audio
    buffer = np.array([])
    buffer_chunks = []
    flag = False
    try:
        print("Starting continuous audio monitoring...")
        while True:
            # Read data from audio stream
            data = np.frombuffer(stream.read(audio_chunk, exception_on_overflow=False), dtype=np.int16)
            buffer = np.append(buffer, data)

            # Maintain buffer size to the last buffer_seconds of audio
            if len(buffer) > sample_rate * buffer_seconds:
                buffer = buffer[int(-sample_rate * buffer_seconds):]

            # Periodically check for speech
            if len(buffer) >= int(sample_rate * buffer_seconds):
                E_s = cal_energy(buffer.copy(), sample_rate)
                # breakpoint()
                # print(E_s)
                if E_s > 260000:

                    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_wav_file:
                        sf.write(temp_wav_file.name, buffer, sample_rate)
                        print(f"Saved detected speech segment to: {temp_wav_file.name}")
                    y, sr = librosa.load(temp_wav_file.name, sr=sample_rate)

                    
                    class_pr =  test(audio=y, sr=sr)
                    if class_pr=='odessa':
                        flag = True
                    if flag==True:
                        print("predicted class is ", class_pr ) 
                    if class_pr!='odessa':
                        flag = False
                    

                print("say")
    except KeyboardInterrupt:
        print("Stopped by User")

    finally:
        # Close the stream
        stream.stop_stream()
        stream.close()
        p.terminate()

                    
        # breakpoint()



        # breakpoint()

